import streamlit as st
import pandas as pd
import time
import json
from bs4 import BeautifulSoup
from io import BytesIO

# --- Selenium ç›¸å…³å¯¼å…¥ ---
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException

# --- æ ¸å¿ƒæŠ“å–é€»è¾‘ (å¢åŠ è°ƒè¯•å¿«ç…§åŠŸèƒ½) ---
def scrape_homedepot_with_selenium(query):
    """
    ä½¿ç”¨Seleniumé©±åŠ¨æµè§ˆå™¨æŠ“å–Home Depoté¡µé¢ï¼Œå¹¶å¢åŠ äº†è°ƒè¯•å¿«ç…§åŠŸèƒ½ã€‚
    ä¸“ä¸ºæœåŠ¡å™¨ç¯å¢ƒä¼˜åŒ–ã€‚

    Args:
        query (str): æœç´¢å…³é”®è¯ã€‚

    Returns:
        list: åŒ…å«å•†å“ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ï¼Œæˆ–åœ¨å‡ºé”™æ—¶è¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    page_results = []
    search_url = f"https://www.homedepot.com/s/{query.replace(' ', '%20')}"
    
    st.write("---")
    st.write("âš™ï¸ **Selenium è‡ªåŠ¨åŒ–æµç¨‹å¯åŠ¨...**")
    
    driver = None
    try:
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_argument(f"--user-data-dir=/tmp/selenium_user_data_{int(time.time())}")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        
        st.write("1. **åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­åˆå§‹åŒ– Chrome æµè§ˆå™¨é©±åŠ¨...**")
        service = Service()
        driver = webdriver.Chrome(service=service, options=options)
        
        st.write(f"2. **æµè§ˆå™¨æ­£åœ¨è®¿é—®ç›®æ ‡ç½‘å€:** {search_url}")
        driver.get(search_url)

        # å»¶é•¿ç­‰å¾…æ—¶é—´å¹¶ç­‰å¾…å…³é”®å…ƒç´ å‡ºç°
        st.write("3. **ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ...** (æœ€é•¿30ç§’)")
        
        # æˆ‘ä»¬ç­‰å¾…é¡µé¢ä¸Šç¬¬ä¸€ä¸ªå•†å“å¡ç‰‡å‡ºç°ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¯”__NEXT_DATA__æ›´å¯é çš„å¯è§æ€§æŒ‡æ ‡
        # é€šè¿‡æµè§ˆå™¨åˆ†æï¼Œå•†å“å¡ç‰‡çš„å®¹å™¨æœ‰ä¸€ä¸ª 'product-grid' çš„CSS module class
        wait = WebDriverWait(driver, 30)
        wait.until(
            EC.any_of(
                EC.presence_of_element_located((By.ID, "__NEXT_DATA__")),
                EC.presence_of_element_located((By.CSS_SELECTOR, "div[data-component='productpod']"))
            )
        )
        st.success("   > é¡µé¢å…³é”®å…ƒç´ å·²åŠ è½½ï¼")

        st.write("4. **è·å–æ¸²æŸ“åçš„å®Œæ•´é¡µé¢ HTML...**")
        html_source = driver.page_source
        
        st.write("5. **ä½¿ç”¨ BeautifulSoup è§£æ HTML...**")
        soup = BeautifulSoup(html_source, 'html.parser')
        
        script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})
        
        if not script_tag:
            st.error("ä¸¥é‡é”™è¯¯ï¼šé¡µé¢å·²åŠ è½½ï¼Œä½†æœªèƒ½æ‰¾åˆ° '__NEXT_DATA__' æ•°æ®å—ã€‚ç½‘ç«™ç»“æ„å¯èƒ½å·²å˜æ›´ã€‚")
            st.code(html_source[:2000], language='html') # æ˜¾ç¤ºHTMLå¤´éƒ¨ä»¥ä¾›åˆ†æ
            return []

        json_data = json.loads(script_tag.string)
        
        products_list = []
        page_props = json_data.get('props', {}).get('pageProps', {})
        if page_props.get('search', {}).get('contentLayouts'):
            content_layouts = page_props['search']['contentLayouts']
            for layout in content_layouts:
                if isinstance(layout, dict) and layout.get('type') == 'PRODUCT_POD' and layout.get('products'):
                    products_list.extend(layout.get('products', []))
        
        if not products_list:
            st.warning("åœ¨'__NEXT_DATA__'ä¸­æœªæ‰¾åˆ°äº§å“åˆ—è¡¨ã€‚")
            return []

        st.write(f"   > **æˆåŠŸè§£æåˆ° {len(products_list)} ä¸ªäº§å“æ¡ç›®!**")
        for product in products_list:
            item_data = product.get('item', product)
            name = item_data.get('productLabel', item_data.get('name', 'N/A'))
            price_info = item_data.get('pricing', {})
            price = price_info.get('specialPrice', {}).get('price') or price_info.get('originalPrice', {}).get('price')

            link = item_data.get('url', '#')
            if link.startswith('/'):
                link = 'https://www.homedepot.com' + link

            image_url = None
            images_list = item_data.get('media', {}).get('images', [])
            if images_list:
                image_url = images_list[0].get('url')

            if name != 'N/A':
                page_results.append({
                    'name': name, 'price': price, 'link': link, 
                    'image_url': image_url or 'https://placehold.co/100x100/e2e8f0/333333?text=No+Image'
                })
        
        return page_results

    except TimeoutException:
        st.error("é¡µé¢åŠ è½½è¶…æ—¶ï¼šåœ¨30ç§’å†…æœªèƒ½æ‰¾åˆ°å…³é”®æ•°æ®ã€‚è¿™å¾ˆå¯èƒ½æ˜¯å› ä¸ºè¢«åçˆ¬è™«æœºåˆ¶æ‹¦æˆªï¼Œæ˜¾ç¤ºäº†éªŒè¯é¡µé¢ã€‚")
        st.write("**è°ƒè¯•å¿«ç…§:** (ä»¥ä¸‹æ˜¯æµè§ˆå™¨åœ¨è¶…æ—¶å‰çš„æœ€åä¸€ä¸ªç”»é¢)")
        try:
            # æˆªå–æµè§ˆå™¨å±å¹•å¿«ç…§å¹¶æ˜¾ç¤º
            png = driver.get_screenshot_as_png()
            st.image(png, caption="æµè§ˆå™¨è¶…æ—¶å¿«ç…§")
            st.info("å¦‚æœä¸Šå›¾æ˜¾ç¤ºäº† CAPTCHA (æˆ‘ä¸æ˜¯æœºå™¨äºº) æˆ– 'Access Denied'ï¼Œåˆ™è¯´æ˜æœåŠ¡å™¨å·²è¯†åˆ«å¹¶é˜»æ­¢äº†æˆ‘ä»¬çš„è‡ªåŠ¨åŒ–è„šæœ¬ã€‚")
        except Exception as ss_e:
            st.error(f"æˆªå–å¿«ç…§å¤±è´¥: {ss_e}")
        return []
    except WebDriverException as e:
        st.error(f"WebDriver é”™è¯¯: {e}")
        return []
    except Exception as e:
        st.error(f"æŠ“å–è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        import traceback
        st.text(traceback.format_exc())
        return []
    finally:
        st.write("6. **å…³é—­æµè§ˆå™¨é©±åŠ¨ï¼Œé‡Šæ”¾èµ„æºã€‚**")
        st.write("---")
        if driver:
            driver.quit()

# --- Streamlit åº”ç”¨ç•Œé¢ ---
st.set_page_config(page_title="Home Depot Selenium çˆ¬è™«", layout="wide")
st.title("ğŸ›’ Home Depot å•†å“æŠ“å–å·¥å…· (è°ƒè¯•ç‰ˆ)")

search_query = st.text_input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ä¾‹å¦‚: 'milwaukee', 'dewalt'):", "milwaukee")

if st.button("ğŸš€ ä½¿ç”¨ Selenium å¼€å§‹æœç´¢"):
    if not search_query:
        st.warning("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼")
    else:
        with st.spinner(f"æ­£åœ¨å¯åŠ¨Seleniumå¹¶æœç´¢ '{search_query}'..."):
            scraped_data = scrape_homedepot_with_selenium(search_query)

        if scraped_data:
            st.success(f"ğŸ‰ **æŠ“å–å®Œæˆï¼å…±è·å¾— {len(scraped_data)} æ¡å•†å“ä¿¡æ¯ï¼**")
            df = pd.DataFrame(scraped_data).drop_duplicates(subset=['name'])
            display_df_data = [{
                "å›¾ç‰‡": row['image_url'],
                "å•†å“åç§°": row['name'],
                "ä»·æ ¼": f"${row['price']}" if row.get('price') else 'N/A',
                "é“¾æ¥": row['link']
            } for _, row in df.iterrows()]
            
            st.dataframe(
                display_df_data,
                column_config={
                    "å›¾ç‰‡": st.column_config.ImageColumn("å›¾ç‰‡é¢„è§ˆ", width="small"),
                    "å•†å“åç§°": st.column_config.TextColumn("å•†å“åç§°", width="large"),
                    "ä»·æ ¼": st.column_config.TextColumn("ä»·æ ¼", width="small"),
                    "é“¾æ¥": st.column_config.LinkColumn("è¯¦æƒ…é“¾æ¥", display_text="ğŸ”— æŸ¥çœ‹å•†å“", width="small")
                }, hide_index=True, use_container_width=True)
        else:
            st.error("æœªèƒ½æŠ“å–åˆ°ä»»ä½•å•†å“ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹çš„æ—¥å¿—å’Œå¿«ç…§ä»¥åˆ†æåŸå› ã€‚")
        
st.markdown("---")
st.markdown("æŠ€æœ¯è¯´æ˜ï¼šæ­¤åº”ç”¨ä½¿ç”¨ `Selenium` é©±åŠ¨åœ¨åå°è¿è¡Œçš„ `Chrome` æµè§ˆå™¨è·å–é¡µé¢æºç ï¼Œå¹¶å†…ç½®äº†å¿«ç…§è°ƒè¯•åŠŸèƒ½ã€‚")
